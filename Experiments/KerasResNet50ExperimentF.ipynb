{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0ZWYAfZD4Lx"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install keras scikit-learn seaborn matplotlib tensorflow\n",
        "\n",
        "# Core libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Computer vision\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Machine learning\n",
        "import keras\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "# Use the ImageDataGenerator from tf.keras\n",
        "# Correct the import statement from tf.keras to tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "klfbXBasD-NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories for dataset\n",
        "train_dir = \"/content/drive/MyDrive/MIT URTC 2025/Experiments/experiment_F/train\"\n",
        "validation_dir = \"/content/drive/MyDrive/MIT URTC 2025/Experiments/experiment_F/val\"\n",
        "test_dir = \"/content/drive/MyDrive/MIT URTC 2025/Experiments/experiment_F/test\""
      ],
      "metadata": {
        "id": "HuC_U45yEBdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing parameters\n",
        "image_size = (224, 224)\n",
        "batch_size = 16\n",
        "num_classes = 3\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=10,\n",
        "    zoom_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {val_generator.samples}\")\n",
        "print(f\"Test samples: {test_generator.samples}\")\n",
        "print(f\"Number of classes: {train_generator.num_classes}\")\n",
        "print(f\"Classes: {list(train_generator.class_indices.keys())}\")"
      ],
      "metadata": {
        "id": "kA5AU1ZjF0CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build ResNet50 model\n",
        "# Import necessary components from Keras/TensorFlow\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_resnet50_model(input_shape, num_classes):\n",
        "    # Use Keras ResNet50 without pre-trained weights (from scratch)\n",
        "    base_model = ResNet50(\n",
        "        include_top=False,\n",
        "        weights=None,       # No pre-trained weights (train from scratch)\n",
        "        input_shape=input_shape,\n",
        "        pooling='avg'       # Global average pooling\n",
        "    )\n",
        "\n",
        "    # Add custom classification head\n",
        "    # Use the imported 'models' and 'layers'\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.Dense(num_classes, activation='softmax', name='predictions')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "input_shape = (*image_size, 3)  # RGB images\n",
        "model = create_resnet50_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "# Use the imported 'Adam' from tensorflow.keras.optimizers\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Model Summary:\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ceHzST1sF1gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import callbacks\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(\n",
        "    'best_model.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Custom callback to track metrics\n",
        "class MetricsCallback(callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_accuracies = []\n",
        "        self.val_accuracies = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.train_losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.train_accuracies.append(logs.get('accuracy'))\n",
        "        self.val_accuracies.append(logs.get('val_accuracy'))\n",
        "\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {logs.get('loss'):.4f} | Val Loss: {logs.get('val_loss'):.4f} | Train Acc: {logs.get('accuracy'):.4f} | Val Acc: {logs.get('val_accuracy'):.4f}\")\n",
        "\n",
        "metrics_callback = MetricsCallback()"
      ],
      "metadata": {
        "id": "OmGOoBImF5I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "epochs = 100\n",
        "\n",
        "print(\"Starting training...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, reduce_lr, checkpoint, metrics_callback],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(\"Training Completed\")"
      ],
      "metadata": {
        "id": "i_FBJxOfGB5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_weights('best_model.h5')"
      ],
      "metadata": {
        "id": "OLQdxVTSHYYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing phase\n",
        "print(\"Evaluating on test set...\")\n",
        "test_generator.reset()  # Reset generator to start from beginning\n",
        "\n",
        "# Get predictions\n",
        "test_steps = test_generator.samples // test_generator.batch_size + 1\n",
        "predictions = model.predict(test_generator, steps=test_steps, verbose=1)\n",
        "\n",
        "# Get true labels\n",
        "test_generator.reset()\n",
        "true_labels = []\n",
        "for i in range(test_steps):\n",
        "    try:\n",
        "        batch_x, batch_y = next(test_generator)\n",
        "        true_labels.extend(np.argmax(batch_y, axis=1))\n",
        "    except StopIteration:\n",
        "        break\n",
        "\n",
        "# Trim predictions to match true labels length\n",
        "predictions = predictions[:len(true_labels)]\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# For ROC AUC, we need the probability scores\n",
        "true_labels_categorical = keras.utils.to_categorical(true_labels, num_classes)\n",
        "roc_auc = roc_auc_score(true_labels_categorical, predictions[:len(true_labels)], multi_class='ovr')\n",
        "mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
        "\n",
        "# Get class names\n",
        "class_names = list(train_generator.class_indices.keys())"
      ],
      "metadata": {
        "id": "AXou8v01HaiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
        "print(f\"Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}, MCC: {mcc:.4f}\")"
      ],
      "metadata": {
        "id": "wI-FdQqOHdsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xM1vP9F5Hi4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(metrics_callback.train_losses, label='Training Loss')\n",
        "ax1.plot(metrics_callback.val_losses, label='Validation Loss')\n",
        "ax1.set_title('Model Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(metrics_callback.train_accuracies, label='Training Accuracy')\n",
        "ax2.plot(metrics_callback.val_accuracies, label='Validation Accuracy')\n",
        "ax2.set_title('Model Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O2awOQy4C2HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model config num_labels: {model.config.num_labels}\")\n",
        "print(f\"Model id2label: {model.config.id2label}\")"
      ],
      "metadata": {
        "id": "TEWjaXalIElK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file: ipython-input-15-559582950\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "# torchvision.transforms is still useful for initial image loading/resizing\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "\n",
        "class TFGradCAM:\n",
        "    \"\"\"\n",
        "    Grad-CAM implementation for TensorFlow Keras Sequential models\n",
        "    \"\"\"\n",
        "    def __init__(self, model, layer_name=None):\n",
        "        self.model = model\n",
        "        self.target_layer = None\n",
        "        self.target_layer_name = layer_name\n",
        "        self.target_layer_found = False\n",
        "\n",
        "        if layer_name is None:\n",
        "            # Attempt to find a suitable default layer (e.g., last convolutional layer)\n",
        "            # Iterate through layers from the end to find the last Conv or Conv-like layer\n",
        "            for layer in reversed(self.model.layers):\n",
        "                 # Check for convolutional layers by type name\n",
        "                if 'conv' in layer.__class__.__name__.lower():\n",
        "                    layer_name = layer.name\n",
        "                    print(f\"Using last convolutional layer found for Grad-CAM: {layer_name}\")\n",
        "                    break\n",
        "            if layer_name is None:\n",
        "                print(\"ERROR: Could not find any convolutional layer for Grad-CAM. Please specify a layer_name.\")\n",
        "                return\n",
        "\n",
        "        # Find the specified layer\n",
        "        try:\n",
        "            self.target_layer = self.model.get_layer(layer_name)\n",
        "            self.target_layer_found = True\n",
        "            print(f\"Using specified layer for Grad-CAM: {layer_name}\")\n",
        "        except ValueError:\n",
        "            print(f\"ERROR: Could not find layer '{layer_name}' in the model.\")\n",
        "            self.target_layer_found = False\n",
        "\n",
        "\n",
        "    def __call__(self, image_tensor, class_idx=None, relu_weights=True, return_attention_map=False):\n",
        "        \"\"\"\n",
        "        Generate Grad-CAM heatmap for a TensorFlow Keras model.\n",
        "\n",
        "        Args:\n",
        "            image_tensor: Input image tensor [1, H, W, C].\n",
        "            class_idx: Class index for which to generate Grad-CAM.\n",
        "                       If None, use the predicted class.\n",
        "            relu_weights: Whether to apply ReLU to the weights (typically True).\n",
        "            return_attention_map: If True, return the attention map only.\n",
        "\n",
        "        Returns:\n",
        "            Visualization with Grad-CAM overlay on original image\n",
        "            or just the attention map if return_attention_map=True,\n",
        "            along with heatmap and original image (as numpy arrays).\n",
        "        \"\"\"\n",
        "        if not self.target_layer_found or self.target_layer is None:\n",
        "            print(\"ERROR: Grad-CAM target layer not found or initialized correctly.\")\n",
        "            return None, None, None\n",
        "\n",
        "        # Ensure image_tensor has a batch dimension\n",
        "        if len(image_tensor.shape) == 3:\n",
        "             image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
        "\n",
        "        # We need to compute gradients with respect to the target layer's output\n",
        "        # and the final prediction for the target class.\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Watch the input tensor\n",
        "            tape.watch(image_tensor)\n",
        "            # Get the output of the target layer\n",
        "            activations = self.model.get_layer(self.target_layer.name).output\n",
        "            # Create a sub-model that outputs the target layer's output and the final output\n",
        "            grad_model = tf.keras.models.Model(inputs=self.model.input, outputs=[self.target_layer.output, self.model.output])\n",
        "\n",
        "            # Get activations and predictions\n",
        "            (activations, predictions) = grad_model(image_tensor)\n",
        "\n",
        "            # If class_idx is None, get the predicted class\n",
        "            if class_idx is None:\n",
        "                class_idx = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "            # Get the score for the target class\n",
        "            target_class_score = predictions[:, class_idx]\n",
        "\n",
        "        # Compute the gradients of the target class score with respect to the target layer's activations\n",
        "        grads = tape.gradient(target_class_score, activations)\n",
        "\n",
        "        # Ensure grads are not None (can happen if layer_name is wrong or disconnected)\n",
        "        if grads is None:\n",
        "            print(f\"ERROR: Gradients could not be computed for layer '{self.target_layer.name}'.\")\n",
        "            print(\"This might happen if the layer is not connected to the output or is not trainable.\")\n",
        "            print(\"Consider trying a different layer.\")\n",
        "            return None, None, None\n",
        "\n",
        "        # Global average pooling of gradients to get importance weights\n",
        "        # In TensorFlow, mean over spatial dimensions (Height and Width)\n",
        "        weights = tf.reduce_mean(grads, axis=(1, 2), keepdims=True)\n",
        "\n",
        "        # Apply ReLU to weights if specified\n",
        "        if relu_weights:\n",
        "            weights = tf.nn.relu(weights)\n",
        "\n",
        "        # Compute weighted activation map (sum of weights * activations)\n",
        "        # activations shape: [1, H', W', C']\n",
        "        # weights shape: [1, 1, 1, C']\n",
        "        # result shape after multiplication: [1, H', W', C']\n",
        "        # sum over channels to get CAM shape: [1, H', W', 1]\n",
        "        cam = tf.reduce_sum(weights * activations, axis=-1, keepdims=True)\n",
        "\n",
        "        # Apply ReLU to the CAM\n",
        "        cam = tf.nn.relu(cam)\n",
        "\n",
        "        # Normalize CAM\n",
        "        # Need to handle case where CAM is all zeros\n",
        "        cam_min = tf.reduce_min(cam)\n",
        "        cam_max = tf.reduce_max(cam)\n",
        "\n",
        "        # Avoid division by zero\n",
        "        if tf.equal(cam_max, cam_min):\n",
        "             print(\"WARNING: CAM has uniform values - all pixels have the same importance.\")\n",
        "             normalized_cam = tf.zeros_like(cam) # Or set to 0.5 or 1 depending on desired default\n",
        "        else:\n",
        "            normalized_cam = (cam - cam_min) / (cam_max - cam_min)\n",
        "\n",
        "        # Remove batch dimension and channel dimension for resizing/visualization\n",
        "        normalized_cam = tf.squeeze(normalized_cam, axis=[0, -1]) # Shape becomes [H', W']\n",
        "\n",
        "        # Resize CAM to match input image size\n",
        "        # Use tf.image.resize\n",
        "        target_height, target_width = image_tensor.shape[1:3]\n",
        "        cam_resized = tf.image.resize(normalized_cam, [target_height, target_width], method='bilinear')\n",
        "\n",
        "        # Convert to numpy for visualization\n",
        "        cam_np = cam_resized.numpy()\n",
        "\n",
        "        if return_attention_map:\n",
        "            return cam_np, None, None # Return only the heatmap\n",
        "\n",
        "        # Convert image tensor to numpy for visualization\n",
        "        # Assuming image_tensor is in [0, 1] range after preprocessing\n",
        "        orig_img = tf.squeeze(image_tensor, axis=0).numpy() # Shape [H, W, C]\n",
        "\n",
        "        # Ensure image is in RGB format if it's grayscale\n",
        "        if orig_img.shape[-1] == 1:\n",
        "            orig_img = np.repeat(orig_img, 3, axis=-1)\n",
        "\n",
        "        # Apply colormap to heatmap (needs cv2)\n",
        "        # Convert cam_np (float 0-1) to uint8 (0-255)\n",
        "        heatmap = cv2.applyColorMap(np.uint8(255 * cam_np), cv2.COLORMAP_JET)\n",
        "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) # Convert from BGR to RGB\n",
        "        heatmap = heatmap.astype('float32') / 255.0 # Normalize to 0-1 range\n",
        "\n",
        "        # Overlay heatmap on original image\n",
        "        # Ensure shapes are compatible for overlay\n",
        "        # orig_img: [H, W, C], heatmap: [H, W, C]\n",
        "        overlay = heatmap * 0.4 + orig_img * 0.6\n",
        "        overlay = np.clip(overlay, 0, 1) # Clip values to be within [0, 1]\n",
        "\n",
        "        return overlay, cam_np, orig_img\n",
        "\n",
        "\n",
        "def visualize_grad_cam_for_brain_mri_tf(model, image_tensor, class_names=None, layer_name=None):\n",
        "    \"\"\"\n",
        "    Visualize Grad-CAM for brain MRI images using a TensorFlow Keras model.\n",
        "\n",
        "    Args:\n",
        "        model: The trained TensorFlow Keras model.\n",
        "        image_tensor: Pre-processed image tensor [1, H, W, C].\n",
        "                      Should be scaled to the range the model was trained on (e.g., 0-1).\n",
        "        class_names: List of class names (if available).\n",
        "        layer_name: Name of the layer to use for Grad-CAM. If None, attempts to find a default.\n",
        "    \"\"\"\n",
        "    # Initialize Grad-CAM with the specified layer\n",
        "    grad_cam = TFGradCAM(model, layer_name=layer_name)\n",
        "\n",
        "    if not grad_cam.target_layer_found:\n",
        "        print(\"Skipping visualization as target layer was not found.\")\n",
        "        return\n",
        "\n",
        "    # Generate Grad-CAM visualization\n",
        "    overlay, heatmap, orig_img = grad_cam(image_tensor)\n",
        "\n",
        "    if overlay is None:\n",
        "        print(\"Failed to generate Grad-CAM visualization.\")\n",
        "        return\n",
        "\n",
        "    # Get the prediction\n",
        "    # Ensure image_tensor has a batch dimension for prediction\n",
        "    if len(image_tensor.shape) == 3:\n",
        "         image_tensor_for_pred = tf.expand_dims(image_tensor, axis=0)\n",
        "    else:\n",
        "        image_tensor_for_pred = image_tensor\n",
        "\n",
        "    predictions = model.predict(image_tensor_for_pred)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    prediction_confidence = np.max(predictions[0])\n",
        "\n",
        "    # Determine class names\n",
        "    if class_names is None:\n",
        "        # Try to infer from the model if possible (less common for Sequential)\n",
        "        # Fallback to generic names\n",
        "        num_output_classes = predictions.shape[1]\n",
        "        class_names = [f\"Class {i}\" for i in range(num_output_classes)]\n",
        "\n",
        "    # Set up the plot\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Plot original image\n",
        "    axes[0].imshow(orig_img, cmap='gray' if orig_img.shape[-1] == 1 else None)\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Plot heatmap\n",
        "    im = axes[1].imshow(heatmap, cmap='jet')\n",
        "    axes[1].set_title('Grad-CAM Heatmap')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)\n",
        "    cbar.set_label('Importance')\n",
        "\n",
        "    # Plot overlay\n",
        "    axes[2].imshow(overlay)\n",
        "    axes[2].set_title('Grad-CAM Overlay')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    # Create title with prediction info\n",
        "    class_name = class_names[predicted_class]\n",
        "    fig.suptitle(f'Class: {class_name} | Confidence: {prediction_confidence:.2f}', fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Return the prediction and heatmap for further analysis\n",
        "    return {\n",
        "        'predicted_class': predicted_class,\n",
        "        'class_name': class_name,\n",
        "        'confidence': prediction_confidence,\n",
        "        'heatmap': heatmap\n",
        "    }\n",
        "\n",
        "\n",
        "# Example usage with multiple layers for TensorFlow\n",
        "def compare_layers_gradcam_tf(model, image_tensor, class_names=None, layers_to_test=None):\n",
        "    \"\"\"\n",
        "    Compare Grad-CAM visualizations from different layers for a TensorFlow model.\n",
        "\n",
        "    Args:\n",
        "        model: The trained TensorFlow Keras model.\n",
        "        image_tensor: Pre-processed image tensor [1, H, W, C], range [0, 1].\n",
        "        class_names: List of class names.\n",
        "        layers_to_test: List of layer names (strings) to visualize.\n",
        "                        If None, attempts to find a selection of convolutional layers.\n",
        "    \"\"\"\n",
        "    # Ensure image_tensor has a batch dimension\n",
        "    if len(image_tensor.shape) == 3:\n",
        "         image_tensor_for_pred = tf.expand_dims(image_tensor, axis=0)\n",
        "    else:\n",
        "        image_tensor_for_pred = image_tensor\n",
        "\n",
        "\n",
        "    if layers_to_test is None:\n",
        "        # Attempt to find a selection of convolutional layers\n",
        "        layers_to_test = []\n",
        "        conv_layers = [layer.name for layer in model.layers if 'conv' in layer.__class__.__name__.lower()]\n",
        "        if len(conv_layers) > 0:\n",
        "            layers_to_test.append(conv_layers[0]) # First conv layer\n",
        "            if len(conv_layers) > 1:\n",
        "                 # Add layers approximately in the middle and towards the end\n",
        "                 layers_to_test.append(conv_layers[len(conv_layers) // 3])\n",
        "                 layers_to_test.append(conv_layers[2 * len(conv_layers) // 3])\n",
        "            layers_to_test.append(conv_layers[-1]) # Last conv layer\n",
        "        else:\n",
        "            print(\"No convolutional layers found to test.\")\n",
        "            return\n",
        "\n",
        "    # Get the prediction once\n",
        "    predictions = model.predict(image_tensor_for_pred)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    prediction_confidence = np.max(predictions[0])\n",
        "\n",
        "    # Determine class names\n",
        "    if class_names is None:\n",
        "        num_output_classes = predictions.shape[1]\n",
        "        class_names = [f\"Class {i}\" for i in range(num_output_classes)]\n",
        "\n",
        "    class_name = class_names[predicted_class]\n",
        "\n",
        "    # Set up the plot\n",
        "    # Add an extra row for the original image\n",
        "    fig, axes = plt.subplots(len(layers_to_test) + 1, 3, figsize=(15, 5 * (len(layers_to_test) + 1)))\n",
        "\n",
        "    # Show original image in the first row\n",
        "    # Convert image_tensor back to numpy without batch dimension\n",
        "    orig_img = tf.squeeze(image_tensor, axis=0).numpy()\n",
        "    if orig_img.shape[-1] == 1:\n",
        "        orig_img = np.repeat(orig_img, 3, axis=-1)\n",
        "\n",
        "\n",
        "    axes[0, 0].imshow(orig_img, cmap='gray' if orig_img.shape[-1] == 1 else None)\n",
        "    axes[0, 0].set_title('Original Image')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # Hide the other two subplots in the first row\n",
        "    axes[0, 1].set_visible(False)\n",
        "    axes[0, 2].set_visible(False)\n",
        "\n",
        "    # Add title to the figure\n",
        "    fig.suptitle(f'Class: {class_name} | Confidence: {prediction_confidence:.2f}', fontsize=16)\n",
        "\n",
        "    # Generate Grad-CAM for each layer\n",
        "    for i, layer_name in enumerate(layers_to_test):\n",
        "        row = i + 1  # Start from second row\n",
        "\n",
        "        print(f\"\\nTesting layer: {layer_name}\")\n",
        "        grad_cam = TFGradCAM(model, layer_name=layer_name)\n",
        "\n",
        "        # Generate Grad-CAM visualization\n",
        "        overlay, heatmap, _ = grad_cam(image_tensor) # Pass the original image_tensor (with batch dim if present)\n",
        "\n",
        "        if overlay is None:\n",
        "            print(f\"Failed to generate Grad-CAM visualization for layer: {layer_name}\")\n",
        "            axes[row, 0].text(0.5, 0.5, f\"Failed: {layer_name}\",\n",
        "                            horizontalalignment='center', verticalalignment='center', fontsize=10, color='red')\n",
        "            axes[row, 0].axis('off')\n",
        "            axes[row, 1].axis('off')\n",
        "            axes[row, 2].axis('off')\n",
        "            continue\n",
        "\n",
        "        # Plot layer name (can be placed on the first subplot of the row)\n",
        "        axes[row, 0].text(0.5, 0.5, f\"Layer: {layer_name}\",\n",
        "                        horizontalalignment='center', verticalalignment='center', fontsize=10)\n",
        "        axes[row, 0].axis('off')\n",
        "\n",
        "        # Plot heatmap\n",
        "        im = axes[row, 1].imshow(heatmap, cmap='jet')\n",
        "        axes[row, 1].set_title('Heatmap')\n",
        "        axes[row, 1].axis('off')\n",
        "\n",
        "        # Plot overlay\n",
        "        axes[row, 2].imshow(overlay)\n",
        "        axes[row, 2].set_title('Overlay')\n",
        "        axes[row, 2].axis('off')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95) # Adjust layout to prevent title overlap\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def run_gradcam_on_image_tf(model, image_path, transform, class_names=None, specific_layer=None):\n",
        "    \"\"\"\n",
        "    Run Grad-CAM on a single image file using a TensorFlow Keras model.\n",
        "\n",
        "    Args:\n",
        "        model: The trained TensorFlow Keras model.\n",
        "        image_path: Path to the image file.\n",
        "        transform: Image transformation pipeline (should output a tensor compatible with model input).\n",
        "        class_names: List of class names.\n",
        "        specific_layer: Optional layer name to use for single Grad-CAM visualization.\n",
        "                        If None, the default is used.\n",
        "    \"\"\"\n",
        "    # Load and preprocess the image using torchvision transforms (can be adapted)\n",
        "    # Assuming torchvision transform returns [C, H, W] tensor [0, 1]\n",
        "    img = Image.open(image_path)\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Apply transform to get PyTorch tensor [C, H, W], typically [0, 1]\n",
        "    input_tensor_torch = transform(img)\n",
        "\n",
        "    # Convert PyTorch tensor [C, H, W] to TensorFlow tensor [1, H, W, C]\n",
        "    # and apply the 1./255 scaling if needed (depends on your transform and model input)\n",
        "    # If your transform already produces [0, 1], no additional scaling needed here.\n",
        "    # Assuming transform outputs [0, 1] range for now.\n",
        "    input_tensor_tf = tf.transpose(tf.convert_to_tensor(input_tensor_torch.numpy()), perm=[1, 2, 0]) # Shape [H, W, C]\n",
        "    input_tensor_tf = tf.expand_dims(input_tensor_tf, axis=0) # Add batch dimension [1, H, W, C]\n",
        "\n",
        "    # Run Grad-CAM with default or specific layer\n",
        "    print(\"\\n--- Single Image Grad-CAM ---\")\n",
        "    result = visualize_grad_cam_for_brain_mri_tf(\n",
        "        model=model,\n",
        "        image_tensor=input_tensor_tf, # Pass the TensorFlow tensor\n",
        "        class_names=class_names,\n",
        "        layer_name=specific_layer # Use specified layer if provided\n",
        "    )\n",
        "\n",
        "    if result:\n",
        "      print(f\"Predicted: {result['class_name']} with confidence {result['confidence']:.4f}\")\n",
        "\n",
        "    # Also compare with different layers\n",
        "    print(\"\\n--- Comparing Layers Grad-CAM ---\")\n",
        "    compare_layers_gradcam_tf(\n",
        "        model=model,\n",
        "        image_tensor=input_tensor_tf, # Pass the TensorFlow tensor\n",
        "        class_names=class_names\n",
        "    )\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "wpQkbI9Ou8t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file: ipython-input-19-3073569956 (Modified)\n",
        "\n",
        "# Example usage with your model structure\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "# Import necessary TensorFlow/Keras modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np # Import numpy\n",
        "# Make sure to import the updated TensorFlow-compatible Grad-CAM functions\n",
        "# If they are in the same notebook cell, no extra import needed.\n",
        "# If you put them in a separate file (e.g., tf_gradcam.py), import them.\n",
        "# from tf_gradcam import run_gradcam_on_image_tf, visualize_existing_tensor_tf, compare_layers_gradcam_tf\n",
        "\n",
        "\n",
        "# Define your transformation pipeline (adjust according to your preprocessing)\n",
        "# Ensure this transform matches the preprocessing applied during training.\n",
        "# Your training data generator used rescale=1./255 and target_size=(224, 224).\n",
        "# This transform resizes to (224, 224) and outputs a PyTorch Tensor in [0, 1].\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize to training size\n",
        "    transforms.ToTensor(),         # Convert to torch.Tensor [C, H, W], range [0, 1]\n",
        "    # No normalization needed here if your model expects input in [0, 1] range\n",
        "])\n",
        "\n",
        "# Set device - This variable is no longer directly used by the TF Grad-CAM functions\n",
        "# but keeping it is harmless if used elsewhere.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define class names based on your dataset\n",
        "class_names = ['glioma', 'meningioma', 'pituitary_tumor']\n",
        "\n",
        "# Option 1: Run Grad-CAM on a single image file\n",
        "# Use the updated function designed for TensorFlow\n",
        "visualize_single_image = run_gradcam_on_image_tf # Rename for clarity if needed\n",
        "\n",
        "# Option 2: Apply to an existing TensorFlow image tensor (if you have one)\n",
        "# The previous visualize_existing_tensor function was also PyTorch-centric.\n",
        "# Let's create a new one or modify the existing logic if needed.\n",
        "# The logic within run_gradcam_on_image_tf or compare_layers_gradcam_tf\n",
        "# handles the tensor format [1, H, W, C] and scaling [0, 1].\n",
        "def visualize_existing_tf_tensor(image_tensor_tf):\n",
        "    \"\"\"\n",
        "    Visualize Grad-CAM on an existing TensorFlow image tensor.\n",
        "\n",
        "    Args:\n",
        "        image_tensor_tf: Pre-processed image tensor [1, H, W, C], range [0, 1].\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Visualizing Existing TensorFlow Tensor ---\")\n",
        "\n",
        "    # Compare different layers to find which one gives the best visualization\n",
        "    compare_layers_gradcam_tf(\n",
        "        model=model,\n",
        "        image_tensor=image_tensor_tf,\n",
        "        class_names=class_names\n",
        "    )\n",
        "\n",
        "    # Visualize with specific layer that showed the best results (if needed)\n",
        "    # Choose based on results from compare_layers_gradcam_tf\n",
        "    # You will need the actual Keras layer name (e.g., \"conv5_block3_out\").\n",
        "    # Inspect your model.summary() to find valid names.\n",
        "    print(\"\\n--- Visualizing with a specific layer (example) ---\")\n",
        "    # Replace \"conv5_block3_out\" with an actual layer name from your model\n",
        "    best_layer_name = \"conv5_block3_out\" # Example\n",
        "    try:\n",
        "        result = visualize_grad_cam_for_brain_mri_tf(\n",
        "            model=model,\n",
        "            image_tensor=image_tensor_tf,\n",
        "            class_names=class_names,\n",
        "            layer_name=best_layer_name\n",
        "        )\n",
        "        if result:\n",
        "            print(f\"Predicted: {result['class_name']} with confidence {result['confidence']:.4f}\")\n",
        "    except ValueError as e:\n",
        "         print(f\"Could not visualize with layer '{best_layer_name}': {e}\")\n",
        "         print(\"Please check the layer name in model.summary()\")\n",
        "\n",
        "\n",
        "\n",
        "# If you have the image file path:\n",
        "# Make sure the path is correct and the image exists.\n",
        "image_file_path = \"/content/drive/MyDrive/MIT URTC 2025/Training_Dataset/test/glioma/1841.jpg\"\n",
        "if os.path.exists(image_file_path):\n",
        "    # Call the function directly with all required arguments\n",
        "    run_gradcam_on_image_tf(\n",
        "        model=model,          # Pass the trained model\n",
        "        image_path=image_file_path, # Pass the image path\n",
        "        transform=transform,    # Pass the transform pipeline\n",
        "        class_names=class_names # Pass class names (optional, but good practice)\n",
        "    )\n",
        "else:\n",
        "    print(f\"Error: Image file not found at {image_file_path}\")\n",
        "\n",
        "# If you have an existing TensorFlow tensor (example):\n",
        "# # Assume you have a tensor named 'my_tf_image_tensor' [1, 224, 224, 3] in [0, 1] range\n",
        "# # Replace this with your actual tensor if you have one\n",
        "# # my_tf_image_tensor = tf.random.uniform(shape=[1, 224, 224, 3]) # Example dummy tensor\n",
        "# # visualize_existing_tf_tensor(my_tf_image_tensor)"
      ],
      "metadata": {
        "id": "pkfJCtfsvFaG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}