{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0ZWYAfZD4Lx"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install keras scikit-learn seaborn matplotlib tensorflow\n",
        "\n",
        "# Core libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Computer vision\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Machine learning\n",
        "import keras\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "# Use the ImageDataGenerator from tf.keras\n",
        "# Correct the import statement from tf.keras to tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klfbXBasD-NZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuC_U45yEBdl"
      },
      "outputs": [],
      "source": [
        "# Directories for dataset\n",
        "train_dir = \"/content/drive/MyDrive/MIT URTC 2025/Experiments/experiment_C/train\"\n",
        "validation_dir = \"/content/drive/MyDrive/MIT URTC 2025/Experiments/experiment_C/val\"\n",
        "test_dir = \"/content/drive/MyDrive/MIT URTC 2025/Experiments/experiment_C/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA5AU1ZjF0CC"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing parameters\n",
        "image_size = (224, 224)\n",
        "batch_size = 16\n",
        "num_classes = 3\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=10,\n",
        "    zoom_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {val_generator.samples}\")\n",
        "print(f\"Test samples: {test_generator.samples}\")\n",
        "print(f\"Number of classes: {train_generator.num_classes}\")\n",
        "print(f\"Classes: {list(train_generator.class_indices.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceHzST1sF1gV"
      },
      "outputs": [],
      "source": [
        "# Build ResNet50 model\n",
        "# Import necessary components from Keras/TensorFlow\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_resnet50_model(input_shape, num_classes):\n",
        "    # Use Keras ResNet50 without pre-trained weights (from scratch)\n",
        "    base_model = ResNet50(\n",
        "        include_top=False,\n",
        "        weights=None,       # No pre-trained weights (train from scratch)\n",
        "        input_shape=input_shape,\n",
        "        pooling='avg'       # Global average pooling\n",
        "    )\n",
        "\n",
        "    # Add custom classification head\n",
        "    # Use the imported 'models' and 'layers'\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.Dense(num_classes, activation='softmax', name='predictions')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "input_shape = (*image_size, 3)  # RGB images\n",
        "model = create_resnet50_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "# Use the imported 'Adam' from tensorflow.keras.optimizers\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Model Summary:\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmGOoBImF5I2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import callbacks\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(\n",
        "    'best_model.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Custom callback to track metrics\n",
        "class MetricsCallback(callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_accuracies = []\n",
        "        self.val_accuracies = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.train_losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.train_accuracies.append(logs.get('accuracy'))\n",
        "        self.val_accuracies.append(logs.get('val_accuracy'))\n",
        "\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {logs.get('loss'):.4f} | Val Loss: {logs.get('val_loss'):.4f} | Train Acc: {logs.get('accuracy'):.4f} | Val Acc: {logs.get('val_accuracy'):.4f}\")\n",
        "\n",
        "metrics_callback = MetricsCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_FBJxOfGB5Z"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "epochs = 100\n",
        "\n",
        "print(\"Starting training...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, reduce_lr, checkpoint, metrics_callback],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(\"Training Completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLQdxVTSHYYK"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "model.load_weights('best_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXou8v01HaiR"
      },
      "outputs": [],
      "source": [
        "# Testing phase\n",
        "print(\"Evaluating on test set...\")\n",
        "test_generator.reset()  # Reset generator to start from beginning\n",
        "\n",
        "# Get predictions\n",
        "test_steps = test_generator.samples // test_generator.batch_size + 1\n",
        "predictions = model.predict(test_generator, steps=test_steps, verbose=1)\n",
        "\n",
        "# Get true labels\n",
        "test_generator.reset()\n",
        "true_labels = []\n",
        "for i in range(test_steps):\n",
        "    try:\n",
        "        batch_x, batch_y = next(test_generator)\n",
        "        true_labels.extend(np.argmax(batch_y, axis=1))\n",
        "    except StopIteration:\n",
        "        break\n",
        "\n",
        "# Trim predictions to match true labels length\n",
        "predictions = predictions[:len(true_labels)]\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# For ROC AUC, we need the probability scores\n",
        "true_labels_categorical = keras.utils.to_categorical(true_labels, num_classes)\n",
        "roc_auc = roc_auc_score(true_labels_categorical, predictions[:len(true_labels)], multi_class='ovr')\n",
        "mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
        "\n",
        "# Get class names\n",
        "class_names = list(train_generator.class_indices.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI-FdQqOHdsj"
      },
      "outputs": [],
      "source": [
        "print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
        "print(f\"Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}, MCC: {mcc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM1vP9F5Hi4r"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2awOQy4C2HS"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(metrics_callback.train_losses, label='Training Loss')\n",
        "ax1.plot(metrics_callback.val_losses, label='Validation Loss')\n",
        "ax1.set_title('Model Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(metrics_callback.train_accuracies, label='Training Accuracy')\n",
        "ax2.plot(metrics_callback.val_accuracies, label='Validation Accuracy')\n",
        "ax2.set_title('Model Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
