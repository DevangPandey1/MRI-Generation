{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Synthetic Brain Tumor MRI Images using Stable Diffusion\n",
        "\n",
        "This notebook showcases the process of fine-tuning a Stable Diffusion model to generate synthetic Magnetic Resonance Imaging (MRI) images of brain tumors."
      ],
      "metadata": {
        "id": "5uGIsLryZIyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "This section handles the initial setup, installing required modules, imports, and drive upload to setup the dataset."
      ],
      "metadata": {
        "id": "HiKTtVwGZvUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade diffusers transformers accelerate torch torchvision datasets"
      ],
      "metadata": {
        "id": "L28Qp9YcqEvD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import random\n",
        "from diffusers import StableDiffusionImg2ImgPipeline, DDPMScheduler\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from google.colab import drive, files"
      ],
      "metadata": {
        "id": "jxrvfzx63-qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Dqn6jh1o4FQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preparation\n",
        "\n",
        "This section defines a custom PyTorch Dataset class to load the brain tumor MRI images and their corresponding text prompts. It also includes the data transformations to be applied to the images and initializes the training dataset."
      ],
      "metadata": {
        "id": "AK9N6tvcadvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = \"/content/drive/MyDrive/MIT URTC 2025/Training_Dataset\"\n",
        "\n",
        "OUTPUT_DIR = \"/content/stable-diffusion-brain-tumor\""
      ],
      "metadata": {
        "id": "H4NyGdC84E1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_LABELS = {\n",
        "    \"meningioma\": \"Meningioma tumor MRI\",\n",
        "    \"glioma\": \"Glioma tumor MRI\",\n",
        "    \"pituitary_tumor\": \"Pituitary tumor MRI\"\n",
        "}"
      ],
      "metadata": {
        "id": "C4IDMCG-4BbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 256\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "RIQ01TFe4QcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MRIDataset(TorchDataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "\n",
        "        for class_name in os.listdir(root_dir):\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            if not os.path.isdir(class_dir):\n",
        "                continue\n",
        "            for fname in os.listdir(class_dir):\n",
        "                img_path = os.path.join(class_dir, fname)\n",
        "                text_prompt = CLASS_LABELS[class_name]\n",
        "                self.samples.append((img_path, text_prompt))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, text_prompt = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return {\"image\": image, \"prompt\": text_prompt}\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "])"
      ],
      "metadata": {
        "id": "MLv6prqs4XBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MRIDataset(os.path.join(DATASET_ROOT, \"train\"), transform=transform)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")"
      ],
      "metadata": {
        "id": "ycuDzEW04ckK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition and Training\n",
        "\n",
        "This section covers loading the pre-trained Stable Diffusion model pipeline, configuring it for training (enabling gradient checkpointing), defining the optimizer (AdamW) and the loss function (MSE), setting up the DDPMScheduler for noise scheduling, and implementing the training loop to fine-tune the UNet component of the pipeline on the custom dataset."
      ],
      "metadata": {
        "id": "1qXii9g_bA4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/sd-turbo\"\n",
        ").to(DEVICE)"
      ],
      "metadata": {
        "id": "AV1yl82D4fNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.unet.enable_gradient_checkpointing()\n",
        "\n",
        "pipe.unet.train()\n",
        "\n",
        "optimizer = AdamW(pipe.unet.parameters(), lr=1e-5)\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "EPOCHS = x #update epoch for your usage\n",
        "\n",
        "scaler = torch.amp.GradScaler(\"cuda\")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    for batch in pbar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        imgs = batch[\"image\"].to(DEVICE)\n",
        "        prompts = batch[\"prompt\"]\n",
        "\n",
        "        with torch.amp.autocast(\"cuda\"):\n",
        "            latents = pipe.vae.encode(imgs).latent_dist.sample()\n",
        "            latents = latents * 0.18215\n",
        "\n",
        "        # Sample noise to add to the latents\n",
        "        noise = torch.randn_like(latents)\n",
        "\n",
        "        # Sample a random timestep for each image\n",
        "        bsz = latents.shape[0]\n",
        "        timesteps = torch.randint(0, pipe.scheduler.config.num_train_timesteps, (bsz,), device=DEVICE).long()\n",
        "\n",
        "        # Add noise to the latents according to the noise magnitude at each timestep\n",
        "        noisy_latents = pipe.scheduler.add_noise(latents, noise, timesteps)\n",
        "\n",
        "        text_embeddings = pipe.text_encoder(\n",
        "            pipe.tokenizer(prompts, padding=\"max_length\", max_length=pipe.tokenizer.model_max_length, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
        "        )[0]\n",
        "\n",
        "        with torch.amp.autocast(\"cuda\"):\n",
        "            model_pred = pipe.unet(noisy_latents, timesteps, encoder_hidden_states=text_embeddings).sample\n",
        "            # Use the target noise (noise) as the target for the model prediction\n",
        "            loss = loss_fn(model_pred.float(), noise.float())\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        pbar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} Average Loss: {avg_loss:.6f}\")"
      ],
      "metadata": {
        "id": "H7oY9ds04i1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"Model saved to {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "TpkqbjR14oTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Generation\n",
        "\n",
        "This section defines a function to generate synthetic images using the fine-tuned Stable Diffusion model. It takes an input image path and a text prompt, and uses the `StableDiffusionImg2ImgPipeline` to generate a new image based on the input and prompt. An example usage is also provided to demonstrate the image generation process. Additionally a class by class generation example is also provided."
      ],
      "metadata": {
        "id": "5LhXGlc3bgMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(input_image_path, text_prompt, strength=0.75, guidance_scale=7.5):\n",
        "    init_image = Image.open(input_image_path).convert(\"RGB\").resize((IMAGE_SIZE, IMAGE_SIZE))\n",
        "    output = pipe(\n",
        "        prompt=text_prompt,\n",
        "        image=init_image,\n",
        "        strength=strength,\n",
        "        guidance_scale=guidance_scale,\n",
        "        num_inference_steps=50,\n",
        "    )\n",
        "    return output.images[0]\n",
        "\n",
        "# Example usage\n",
        "sample_image = generate_image(\n",
        "    input_image_path=os.path.join(DATASET_ROOT, \"test\", \"pituitary_tumor\", os.listdir(os.path.join(DATASET_ROOT, \"test\", \"pituitary_tumor\"))[0]),\n",
        "    text_prompt=CLASS_LABELS[\"pituitary_tumor\"]\n",
        ")\n",
        "sample_image.save(\"/content/generated_sample_pituitary_tumor.png\")\n",
        "print(\"Generated image saved.\")"
      ],
      "metadata": {
        "id": "D0xIZo4l4pni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images_for_class(\n",
        "    class_name,\n",
        "    num_images=5000,\n",
        "    strength=0.75,\n",
        "    guidance_scale=7.5,\n",
        "    save_dir=\"/content/generated_samples\"\n",
        "):\n",
        "    class_dir = os.path.join(save_dir, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    input_dir = os.path.join(DATASET_ROOT, \"train\", class_name)\n",
        "    input_files = os.listdir(input_dir)\n",
        "\n",
        "    for i in tqdm(range(num_images), desc=f\"Generating {class_name}\"):\n",
        "        input_image_path = os.path.join(input_dir, random.choice(input_files))\n",
        "\n",
        "        img = generate_image(\n",
        "            input_image_path=input_image_path,\n",
        "            text_prompt=CLASS_LABELS[class_name],\n",
        "            strength=strength,\n",
        "            guidance_scale=guidance_scale\n",
        "        )\n",
        "\n",
        "        out_path = os.path.join(class_dir, f\"{class_name}_{i:03d}.png\")\n",
        "        img.save(out_path)\n",
        "\n",
        "    print(f\"Saved {num_images} images for {class_name} to {class_dir}\")"
      ],
      "metadata": {
        "id": "0B8pywcuNVh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cls in CLASS_LABELS.keys():\n",
        "    generate_images_for_class(\n",
        "        class_name=cls,\n",
        "        num_images=5000,\n",
        "        save_dir=\"/content/generated_samples\"\n",
        "    )"
      ],
      "metadata": {
        "id": "1eLTIeyvNXWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/stable-diffusion-brain-tumor.zip /content/stable-diffusion-brain-tumor\n",
        "!zip -r /content/generated_samples.zip /content/generated_samples\n",
        "\n",
        "files.download('/content/generated_samples.zip')"
      ],
      "metadata": {
        "id": "5R3gAU7lD6Tu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}